{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0403e43-5b95-4a91-b0a0-9f052bd2824b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from lime import lime_tabular\n",
    "from lime import submodular_pick\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.style.use(\"seaborn\")\n",
    "\n",
    "\n",
    "# Check loops\n",
    "def checkLoops(expName):\n",
    "    data = ds.loc[:,['caseId', 'activity']]\n",
    "\n",
    "    actCount = data.groupby(data.columns.tolist()).size().reset_index().\\\n",
    "                        rename(columns={0:'records'})\n",
    "    print(actCount.describe())\n",
    "    #print(actCount[:20])\n",
    "    \n",
    "def checkCorrelation():\n",
    "    ds['Accept Claim'] = ds['Accept Claim'].astype(bool)\n",
    "    print('Accept == label (1)', ds['Accept Claim'].equals(ds['label']))\n",
    "\n",
    "    ds['Reject Claim'] = ds['Reject Claim'].astype(bool)\n",
    "    print('Reject == label (0)', ds['Reject Claim'].equals(~ds['label']))\n",
    "    \n",
    "# Delete out loops, Input: trace (lista), Ouput: traceSemLoop (lista)\n",
    "def dropLoopsInTraces(traceList):\n",
    "    prev = object()\n",
    "    traceList = [prev := v for v in traceList if prev != v]\n",
    "    return traceList\n",
    "\n",
    "# Transform the log into dataset of traces\n",
    "def f_Traces(x):\n",
    "    return pd.Series(dict(trace='%s' % ','.join(x['activity']),\n",
    "                      nrEvents=x['activity'].count(),\n",
    "                      target=int(x[target].mean())))\n",
    "\n",
    "# Transform the log into dataset of traces considering resources\n",
    "def f_TracesComplex(x):\n",
    "    return pd.Series(dict(tracea='%s' % ','.join(x['activity']),\n",
    "                          tracer='%s' % ','.join(x['Resource']),\n",
    "                          nrEvents=x['activity'].count(),\n",
    "                          target=int(x[target].mean())))\n",
    "\n",
    "# Load event log data\n",
    "def loadData(data, column_caseId, column_activity):   \n",
    "    global ds, target, class_names, expName\n",
    "    ds = pd.read_csv('data/' + data.split('_')[0] + '.csv', sep=',')\n",
    "    target = 'label'\n",
    "    class_names = [0, 1]\n",
    "    ds = ds.rename(columns={column_caseId: \"caseId\", column_activity: \"activity\"})\n",
    "    expName = data\n",
    "    print(\"Data loaded...\")\n",
    "\n",
    "# Pre-process data: simple indexing, considering trace positions,  Input: dataset of traces (dataframe), Ouput: dataset of activity per position in trace (dataframe)\n",
    "def simpleIndexingNoLoops():\n",
    "    global ds\n",
    "    ds = ds.groupby('caseId').apply(f_Traces)\n",
    "    ds_new = pd.DataFrame(columns=['caseId', 'trace', 'nrEvents', target])\n",
    "    for item in ds.iterrows():\n",
    "        noduplicates = dropLoopsInTraces(item[1][0].split(','))\n",
    "        ds_new.loc[len(ds_new)] = [int(item[0]), ','.join(noduplicates), len(noduplicates), int(item[1][2])]\n",
    "\n",
    "    ds_new[['a1', 'a2', 'a3', 'a4', 'a5', 'a6', 'a7', 'a8', 'a9', 'a10', 'a11', 'a12', 'a13']] = ds_new['trace'].str.split(',', expand=True)\n",
    "    ds_new = ds_new.drop(['caseId', 'trace', 'nrEvents'], axis=1)\n",
    "    ds_new.to_csv('results/' + expName + '_traces.csv')\n",
    "    ds = ds_new.copy()\n",
    "    print(\"Data preprocessed... SIMPLE-INDEXING ENCODING\")\n",
    "\n",
    "    \n",
    "# Pre-process data: frequency indexing, considering frequency of occurrence of an activity in the trace\n",
    "def frequencyIndexingWithLoops():\n",
    "    global ds\n",
    "    ds.loc[ds.activity =='Accept Claim','activity']='Decide claim'\n",
    "    ds.loc[ds.activity =='Reject Claim','activity']='Decide claim'\n",
    "    ds_new = pd.DataFrame()\n",
    "    ds_new[['caseId', 'activity','label']] = ds[['caseId', 'activity','label']].copy()\n",
    "    ds_new['val'] = 1\n",
    "    ds_new = ds_new.groupby(['caseId', 'label', 'activity'])['val'].sum().unstack(fill_value=0)\n",
    "    ds_new.reset_index(level = 'label', inplace=True)\n",
    "    ds_new.reset_index(level = 'caseId', inplace=True)\n",
    "    ds_new.drop(['caseId'], axis = 1, inplace=True)\n",
    "    ds_new.to_csv('results/' + expName + '_frequencytraces.csv')\n",
    "    ds = ds_new.copy()\n",
    "    print(\"Data preprocessed... FREQUENCY-INDEXING ENCODING\")\n",
    "\n",
    "# Apply one-hot encoding and split data\n",
    "def encodingAndSplitData():\n",
    "    global X, y, X_train, X_test, y_train, y_test\n",
    "\n",
    "    X = pd.get_dummies(ds.drop(columns=[target]))\n",
    "    y = ds[target].astype(bool)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  # Set the random_state parameter to 42 for getting the same split\n",
    "    print(\"Data splitted...\")\n",
    "    print('X_train shape: ', X_train.shape)\n",
    "    print('y_train shape: ', y_train.shape)\n",
    "    print('X_test shape: ', X_test.shape)\n",
    "    print('y_test shape: ', y_test.shape)\n",
    "    \n",
    "# Train um RandomForestClassifier from ScikitLearn\n",
    "def trainRFModel():\n",
    "    global model\n",
    "    model = RandomForestClassifier(random_state = np.random.seed(42))\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    print('Model trained... RFC score: ', score)\n",
    "          \n",
    "\n",
    "# Apply Lime for an instance, Input: CaseId (int), Output: LimeExp (lime object)\n",
    "def applyLimeIn(points, nrFeatures):\n",
    "    explainer = lime_tabular.LimeTabularExplainer(\n",
    "                                                    training_data=np.array(X_train),\n",
    "                                                    feature_names=X_train.columns,\n",
    "                                                    class_names=class_names,\n",
    "                                                    mode='classification')\n",
    "\n",
    "    exp_points = []\n",
    "    exp_list = []\n",
    "\n",
    "    for idx in points:\n",
    "        exp = explainer.explain_instance(data_row=X_train.loc[idx], predict_fn=model.predict_proba, num_features=nrFeatures)\n",
    "        exp_list = exp.as_list()\n",
    "        exp_list.append(round(model.predict_proba([X_train.loc[idx]])[0, 0], 2))\n",
    "        exp_list.append(round(model.predict_proba([X_train.loc[idx]])[0, 1], 2))\n",
    "        exp_list.append(ds.loc[idx, target]) #exp_list.append(ds_new.loc[idx, target])\n",
    "        exp_list.append(idx)\n",
    "        exp_points.append(exp_list)\n",
    "    fileName = \"results/\"+ expName + \"_explanations.csv\"\n",
    "    with open(fileName, \"w\") as file:\n",
    "        for row in exp_points:\n",
    "            file.write(\"%s\\n\" % ';'.join(str(col) for col in row))\n",
    "    print(\"Explanations file created... \" + fileName)\n",
    "\n",
    "    \n",
    "# Apply SP-Lime\n",
    "def applySPLimeIn(sampleSize, nrFeatures, nrExplanations):\n",
    "    explainer = lime_tabular.LimeTabularExplainer(\n",
    "                                                    training_data=np.array(X_train),\n",
    "                                                    feature_names=X_train.columns,\n",
    "                                                    class_names=class_names,\n",
    "                                                    mode='classification')\n",
    "\n",
    "    training_data=np.array(X_train)\n",
    "    sp_obj = submodular_pick.SubmodularPick(explainer, data=training_data, predict_fn=model.predict_proba, sample_size=sampleSize, num_features=nrFeatures, num_exps_desired=nrExplanations)\n",
    "    exp_points = sp_obj.sp_explanations[9].as_list()\n",
    "    fileName = \"results/\"+ expName + \"_explanationsSPLIME.csv\"\n",
    "    with open(fileName, \"w\") as file:\n",
    "        for row in exp_points:\n",
    "            file.write(\"%s\\n\" % ';'.join(str(col) for col in row))\n",
    "    print(\"Explanations with SP-LIME file created... \"+fileName)\n",
    "\n",
    "# Plot results from file generated by the LIME module, Input: Number of figures per row (int), Experiment Name (str)\n",
    "def plotLimeResults(plotsPerRow, expName):        \n",
    "    i, j = 0, 0\n",
    "    fileName = \"results/\"+ expName + \"_explanations.csv\"\n",
    "    with open(fileName, \"r\") as file:\n",
    "        exp_points = list(file)\n",
    "    exp_points = [x.rstrip() for x in exp_points]\n",
    "    exp_points = [list(x.split(';')) for x in exp_points]\n",
    "\n",
    "    # Graph multiplot\n",
    "    fig, axs = plt.subplots(nrows=math.ceil(len(exp_points) / plotsPerRow), ncols=plotsPerRow, constrained_layout=True, figsize=(20, 20))  # #squeeze=False, you can force the result to be a 2D-array, independant of the number or arrangement of the subplots\n",
    "    fig.suptitle('Experiment: %s' % expName, fontsize=20)  # title for entire figure\n",
    "\n",
    "    exp_list = []\n",
    "    for exp_list in exp_points:\n",
    "        exp_list = [x.strip('(') for x in exp_list]\n",
    "        exp_list = [x.strip(')') for x in exp_list]\n",
    "        exp_list = [x.split(', ') for x in exp_list]\n",
    "        names = [x[0].strip(\"\\'\") for x in exp_list[:-4]]  # Y\n",
    "        names = [n.rpartition('.0')[0] for n in names]\n",
    "        vals = [round(float(x[1]), 3) for x in exp_list[:-4]]  # X\n",
    "        pos = np.arange(len(exp_list) - 4) + .5\n",
    "        prob0 = exp_list[len(exp_list) - 4][0]\n",
    "        prob1 = exp_list[len(exp_list) - 3][0]\n",
    "        y_target = exp_list[len(exp_list) - 2][0]\n",
    "        idx = exp_list[len(exp_list) - 1][0]\n",
    "        vals.reverse()\n",
    "        names.reverse()\n",
    "        colors = ['green' if x > 0 else 'red' for x in vals]\n",
    "        axs[i][j].set_title('Case Id: %s\\nProbability for class 0 = %s \\nProbability for class 1 = %s\\n Target/Y: %s' % (idx,\n",
    "                                                                                                                      str(prob0),\n",
    "                                                                                                                      str(prob1),\n",
    "                                                                                                                      y_target))\n",
    "        axs[i][j].barh(pos, vals, align='center', color=colors)\n",
    "        axs[i][j].set_yticks(pos, names)\n",
    "        j += 1\n",
    "        if j % plotsPerRow == 0:\n",
    "            i += 1\n",
    "            j = 0\n",
    "\n",
    "    plt.show()\n",
    "    fig.savefig(str(\"results/\" + expName + \"_plotLime.jpg\"), bbox_inches='tight')\n",
    "    print('Figure saved...' + \"results/\" + expName + \"_plotLime.jpg\")\n",
    "\n",
    "# plot LIME-SP results in a a global way ***not working yet***\n",
    "def plotLimeSPResults(sp_obj):\n",
    "    #Plot explanations\n",
    "    [explainer.as_pyplot_figure(label=explainer.available_labels()[0]) for explainer in sp_obj.sp_explanations];\n",
    "    # Make it into a dataframe SP-LIME\n",
    "    W_pick=pd.DataFrame([dict(this.as_list(this.available_labels()[0])) for this in sp_obj.sp_explanations]).fillna(0)\n",
    "    # Getting SP predictions\n",
    "    W_pick['prediction'] = [this.available_labels()[0] for this in sp_obj.sp_explanations]\n",
    "    W_pick.to_csv(\"results/\"+ expName + \"_expSPLime.csv\")\n",
    "    print('Results saved...' + \"results/\" + expName + \"_resultsSPLime.jpg\")\n",
    "    \n",
    "    #Making a dataframe of all the explanations of sampled points SIMPLE - LIME\n",
    "    W=pd.DataFrame([dict(this.as_list(this.available_labels()[0])) for this in sp_obj.explanations]).fillna(0)\n",
    "    W['prediction'] = [this.available_labels()[0] for this in sp_obj.explanations]\n",
    "    W.to_csv(\"results/\"+ expName + \"_expLime.csv\")\n",
    "    print('Results saved...' + \"results/\" + expName + \"_resultsLime.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7047afb8-acf2-486e-aa4b-0f8e3c4dc461",
   "metadata": {},
   "outputs": [],
   "source": [
    "expName = 'trainMaggiOriginal_artigoWithDuplicates3'\n",
    "loadData(expName, 'Case ID', 'Activity')\n",
    "#checkLoops(expName)\n",
    "\n",
    "# Select type of modeling for traces in log\n",
    "#simpleIndexingNoLoops()\n",
    "frequencyIndexingWithLoops()\n",
    "#checkCorrelation()\n",
    "\n",
    "global ds\n",
    "#ds = ds.drop(['Accept Claim', 'Reject Claim'], axis=1)\n",
    "\n",
    "# dropping ALL duplicate values\n",
    "ds.drop_duplicates(keep = \"first\", inplace = True)\n",
    "\n",
    "# Train a ML model\n",
    "encodingAndSplitData()\n",
    "trainRFModel()\n",
    "\n",
    "# Basic LIME \n",
    "# points=[704, 780, 1047, 1710, 2379, 2556, 2584, 2721]\n",
    "# applyLimeIn(points, 17)\n",
    "# plotLimeResults(2, expName)\n",
    "\n",
    "# Not working complete yet\n",
    "# SP-LIME\n",
    "explainer = lime_tabular.LimeTabularExplainer(\n",
    "                                                    training_data=np.array(X_train),\n",
    "                                                    feature_names=X_train.columns,\n",
    "                                                    class_names=class_names,\n",
    "                                                    mode='classification')\n",
    "\n",
    "training_data=np.array(X_train)\n",
    "sp_obj = submodular_pick.SubmodularPick(explainer, data=training_data, predict_fn=model.predict_proba, num_features=20, num_exps_desired=10)\n",
    "\n",
    "plotLimeSPResults(sp_obj)\n",
    "#-------- ok ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d795d9aa-729d-496f-8290-b7c014c7c1c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Archive', 'Contact Hospital', 'Create Questionnaire', 'Decide claim',\n",
       "       'High Insurance Check', 'High Medical History', 'Low Insurance Check',\n",
       "       'Low Medical History', 'Prepare Notification Content',\n",
       "       'Receive Questionnaire Response', 'Register',\n",
       "       'Send Notification by Phone', 'Send Notification by Post',\n",
       "       'Send Notification by e-mail', 'Send Questionnaire',\n",
       "       'Skip Questionnaire'],\n",
       "      dtype='object', name='activity')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0c1a526-8b57-48e3-a7cc-dd4dcb605d33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp_obj.explanations[2].available_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1f71e8b-3128-4882-9147-f97a18221629",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7944\\240275192.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mdfl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mexp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msp_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msp_explanations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0ml\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthis_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"exp number\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mdfl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\lime\\explanation.py\u001b[0m in \u001b[0;36mas_list\u001b[1;34m(self, label, **kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m         \"\"\"\n\u001b[0;32m    140\u001b[0m         \u001b[0mlabel_to_use\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"classification\"\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdummy_label\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m         \u001b[0mans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdomain_mapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_exp_ids\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocal_exp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel_to_use\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[0mans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mans\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mans\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({})\n",
    "for this_label in range(3):\n",
    "    dfl=[]\n",
    "    for i,exp in enumerate(sp_obj.sp_explanations):\n",
    "        l=exp.as_list(label=this_label)\n",
    "        l.append((\"exp number\",i))\n",
    "        dfl.append(dict(l))\n",
    "    dftest=pd.DataFrame(dfl)\n",
    "    df=df.append(pd.DataFrame(dfl,index=[iris.target_names[this_label] for i in range(len(sp_obj.sp_explanations))]))\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
